{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  #Open CV - Computer Vision\n",
    "from keras.models import load_model \n",
    "import numpy as np\n",
    "from collections import deque #Queue (Stack and Queue)\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x0000022575DD3C88>\n"
     ]
    }
   ],
   "source": [
    "model1 = load_model('model/devanagari_model_refined.h5')\n",
    "print(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_count = {0: 'Check', 1: '01_ka', 2: '02_kha', 3: '03_ga', 4: '04_gha', 5: '05_kna',\n",
    "               6: '06_cha', 7: '07_chha', 8: '08_ja', 9: '04_jha', 10: '10_yna',\n",
    "               11: '11_taamatar', 12: '12_thaa', 13: '13_da', 14: '14_dhaa', 15: '15_adna',\n",
    "               16: '16_tabala', 17: '17_tha', 18: '18_da', 19: '19_dha', 20: '20_na',\n",
    "               21: '21_pa', 22: '22_pha', 23: '23_ba', 24: '24_bha', 25: '25_ma',\n",
    "               26: '26_yaw', 27: '27_ra', 28: '28_la', 29: '29_waw', 30: '30_motosaw',\n",
    "               31: '31_petchiryakha', 32: '32_patalosaw', 33: '33_ha', 34: '34_chhya', 35: '35_tra',\n",
    "               36: '36_gya', 37: '37_Check'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_predict(model, image): #To predict data from webcam\n",
    "    processed = keras_process_image(image)\n",
    "    print(\"processed: \"+str(processed.shape))\n",
    "    pred_probab = model.predict(processed)[0]\n",
    "    #Get class with max probability \n",
    "    pred_class = list(pred_probab).index(max(pred_probab))\n",
    "    return max(pred_probab), pred_class\n",
    "\n",
    "#Gets image, resize image to a 32x32 pixel size. Then convert to np array and reshape/ \n",
    "def keras_process_image(img):\n",
    "    image_x = 32\n",
    "    image_y = 32\n",
    "    img = cv2.resize(img, (image_x, image_y))\n",
    "    img = np.array(img, dtype=np.float32)\n",
    "    # -1 to get last value. X,y is height,width and 1 is number of channels\n",
    "    img=  np.reshape(img, (-1, image_x, image_y, 1))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5214.0\n",
      "processed: (1, 32, 32, 1)\n",
      "1 0.47232386\n",
      "7024.5\n",
      "processed: (1, 32, 32, 1)\n",
      "19 0.19123149\n",
      "4079.0\n",
      "processed: (1, 32, 32, 1)\n",
      "21 0.32669625\n",
      "4139.5\n",
      "processed: (1, 32, 32, 1)\n",
      "24 0.41786933\n",
      "4185.5\n",
      "processed: (1, 32, 32, 1)\n",
      "25 0.2902307\n",
      "270.5\n",
      "3757.0\n",
      "processed: (1, 32, 32, 1)\n",
      "27 0.7268657\n",
      "4999.0\n",
      "processed: (1, 32, 32, 1)\n",
      "28 0.2600375\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)  #Get webcam feed\n",
    "Lower_blue = np.array([90, 50, 50])  #BGR format. Capture the blue colours\n",
    "Upper_blue = np.array([130, 255, 255])  #When camera captures value between 110-130, then it's probably a blue, so that's what we want\n",
    "pred_class=0 \n",
    "pts = deque(maxlen=512) #queue\n",
    "blackboard = np.zeros((480, 640, 3), dtype=np.uint8) #Actual drawings are placed in this blackboard\n",
    "digit = np.zeros((200, 200, 3), dtype=np.uint8) \n",
    "\n",
    "while (True):  #While we are actually capturing anything\n",
    "    ret, img = cap.read() #Get image from webcam\n",
    "    img = cv2.flip(img, 1)  #Flip image coz it'll probably be mirrored\n",
    "    imgHSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV) #Convert to HSV\n",
    "    mask = cv2.inRange(imgHSV, Lower_blue, Upper_blue) #Mask between lower bound and upper bound blue. If anything between these 2, we want\n",
    "    blur = cv2.medianBlur(mask, 15) #Blue image to get rid of edges\n",
    "    blur = cv2.GaussianBlur(blur, (5,5), 0)\n",
    "    thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1] #ignore values beyond threshold\n",
    "    cnts,_ = cv2.findContours(thresh.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)[-2:] #diff features on image beyond threshold\n",
    "    center = None\n",
    "\n",
    "    if(cnts is None):\n",
    "        print(\"None\")\n",
    "    elif(len(cnts) >= 1): #if contour is present (Blue colour is present)\n",
    "        contour = max(cnts, key=cv2.contourArea) #Take max of contour and calc area\n",
    "        if(cv2.contourArea(contour) > 250):\n",
    "            ((x,y), radius) = cv2.minEnclosingCircle(contour) #enclose contour in circle to ensure where contour is \n",
    "            cv2.circle(img, (int(x), int(y)), int(radius), (0, 255, 255), 2)  #Creates circle around contour\n",
    "            cv2.circle(img, center, 5, (0, 0, 255, -1))\n",
    "            M = cv2.moments(contour)\n",
    "            center = (int(M['m10'] / M['m00']), int(M['m01'] / M['m00']))\n",
    "            pts.appendleft(center) #Insers center in a queue. \n",
    "            for i in range(1, len(pts)):\n",
    "                if(pts[i-1] is None or pts[i] is None):\n",
    "                    continue\n",
    "                #Draw line in blackboard of black color and length 10\n",
    "                cv2.line(blackboard, pts[i-1], pts[i], (255, 255, 255), 10)\n",
    "                #Draw line in image of red color and size 5\n",
    "                cv2.line(img, pts[i-1], pts[i], (0, 0, 255), 5)\n",
    "    elif(len(cnts) ==0): #Suppose we have removed blue colour on screen. No contours\n",
    "        if(len(pts) != []):\n",
    "            #Convert to gray colour, blur, get threshold and get contour\n",
    "            blackboard_gray = cv2.cvtColor(blackboard, cv2.COLOR_BGR2GRAY)\n",
    "            blur1 = cv2.medianBlur(blackboard_gray, 15)\n",
    "            blur1 = cv2.GaussianBlur(blur1, (5,5), 0)\n",
    "            thresh1 = cv2.threshold(blur1, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "            blackboard_cnts, _ = cv2.findContours(thresh1.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)[-2:]\n",
    "            if(len(blackboard_cnts)) >=1:\n",
    "                #Get max of contour\n",
    "                cnt = max(blackboard_cnts, key=cv2.contourArea)\n",
    "                #print area\n",
    "                print(cv2.contourArea(cnt))\n",
    "                #If area>2000, then it is noise. Might be blue color in background, etc\n",
    "                if cv2.contourArea(cnt) > 2000:\n",
    "                    x,y,w,h = cv2.boundingRect(cnt) #Bound contour into rectangle\n",
    "                    #Convert blackboard gray image to digit variable\n",
    "                    digit = blackboard_gray[y:y + h, x:x + w]\n",
    "                    #newImage = process_letter(digit)\n",
    "                    pred_probab, pred_class = keras_predict(model1, digit)\n",
    "                    print(pred_class, pred_probab)\n",
    "\n",
    "        pts = deque(maxlen=512)\n",
    "        blackboard = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "    cv2.putText(img, \"Conv network: \"+str(letter_count[pred_class]), (10, 470),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "    cv2.imshow(\"Contours\", thresh)\n",
    "    cv2.imshow(\"Frame\", img)\n",
    "    k = cv2.waitKey(1)\n",
    "    if  k & 0xFF == 27 or ret==False:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
